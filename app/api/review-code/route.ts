import { NextRequest, NextResponse } from "next/server"
import { generateText } from "ai"
import {
  providerCandidates,
  resolveAIConfig,
  type AIConfigPayload,
} from "@/lib/ai-config"
import { getLanguageModel } from "@/lib/server/ai-model"
import {
  getMentorPersonaInstruction,
  getMentorLanguageInstruction,
  resolveMentorLanguage,
  type MentorLanguage,
} from "@/lib/mentor-language"

interface TestResult {
  passed: boolean
  input: string
  expected: string
  actual: string
}

interface ReviewRequest {
  code: string
  problemTitle: string
  problemDescription: string
  testResults: TestResult[]
  allTestsPassed: boolean
  language?: MentorLanguage
  aiConfig?: Partial<AIConfigPayload>
}

function generateFallbackReviewFeedback(
  language: MentorLanguage,
  passedCount: number,
  totalCount: number,
  allTestsPassed: boolean,
  note: "no-key" | "service-error"
): string {
  const statusNote =
    note === "no-key"
      ? language === "ko"
        ? "ì§€ê¸ˆì€ API Keyê°€ ì—†ì–´ë„, í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê¸°ë°˜ìœ¼ë¡œ ê°™ì´ ë””ë²„ê¹…/ê°œì„ í•´ë³¼ ìˆ˜ ìžˆì–´."
        : "No API key is configured, so deep AI analysis is limited. Here is a mentor-style review."
      : language === "ko"
        ? "AI ì—°ê²°ì´ ìž ê¹ ë¶ˆì•ˆì •í•˜ì§€ë§Œ, ì§€ê¸ˆ ê²°ê³¼ ê¸°ì¤€ìœ¼ë¡œ ê°™ì´ ì´ì–´ê°€ë³´ìž."
        : "AI service is temporarily unstable, but here is a mentor-style review from current results."

  if (language === "ko") {
    if (!allTestsPassed) {
      return `ì¢‹ì•„, ì§€ê¸ˆì€ íš¨ìœ¨ ì–˜ê¸°ë³´ë‹¤ ì™œ ì‹¤íŒ¨í–ˆëŠ”ì§€ë¶€í„° ê°™ì´ ìž¡ìž.
í˜„ìž¬ í†µê³¼ëŠ” ${passedCount}/${totalCount}ê°œì•¼.

ì‹¤íŒ¨ ì¼€ì´ìŠ¤ 1ê°œë§Œ ê³¨ë¼ì„œ ìž…ë ¥ -> ì¡°ê±´ ë¶„ê¸° -> ë°˜í™˜ê°’ ìˆœì„œë¡œ ë”°ë¼ê°€ë³´ìž.
íŠ¹ížˆ ê²½ê³„ê°’(ë¹ˆ ìž…ë ¥, ê¸¸ì´ 1, ì¤‘ë³µ)ì—ì„œ ì¡°ê±´ì´ ë¨¼ì € íƒˆë½í•˜ëŠ”ì§€ í™•ì¸í•´ë´.

ì‹¤íŒ¨í•œ ì¼€ì´ìŠ¤ í•˜ë‚˜ ë¶™ì—¬ì£¼ë©´, ë‚´ê°€ ê·¸ íë¦„ì„ í•œ ì¤„ì”© ê°™ì´ ë””ë²„ê¹…í•´ì¤„ê²Œ.

(${statusNote})`
    }

    return `Pass! ìž˜í–ˆë‹¤ ðŸ‘ ì§€ê¸ˆ í†µê³¼ëŠ” ${passedCount}/${totalCount}ê°œì•¼.

ì´ì œ í”„ë¡œë•ì…˜ ê´€ì ìœ¼ë¡œ í•œ ë‹¨ê³„ë§Œ ë” ì˜¬ë ¤ë³´ìž.
- ì‹œê°„ë³µìž¡ë„: ì¤‘ì²© ë£¨í”„ê°€ ìžˆìœ¼ë©´ O(n^2)ì¼ ê°€ëŠ¥ì„±ì´ ì»¤. Map/Setìœ¼ë¡œ O(n)ê¹Œì§€ ì¤„ì¼ ìˆ˜ ìžˆëŠ”ì§€ ë³´ìž.
- ê³µê°„ë³µìž¡ë„: ë³´ì¡° ìžë£Œêµ¬ì¡°ë¥¼ ì“°ëŠ” ëŒ€ì‹  ë°˜ë³µì„ ì¤„ì´ëŠ” íŠ¸ë ˆì´ë“œì˜¤í”„ê°€ ë§žëŠ”ì§€ í™•ì¸í•´ë³´ìž.
- ë„¤ì´ë°: i, tmp ê°™ì€ ì´ë¦„ì€ ì—­í•  ê¸°ë°˜(countMap, left, current)ìœ¼ë¡œ ë°”ê¾¸ë©´ ìœ ì§€ë³´ìˆ˜ê°€ í›¨ì”¬ ì‰¬ì›Œì ¸.

ì›í•˜ë©´ ë„¤ ì½”ë“œ ê¸°ì¤€ìœ¼ë¡œ ì–´ë–¤ ì¤„ì„ ì–´ë–»ê²Œ ë°”ê¾¸ë©´ ì¢‹ì€ì§€ ë°”ë¡œ ì œì•ˆí•´ì¤„ê²Œ.

(${statusNote})`
  }

  if (!allTestsPassed) {
    return `Let us focus on debugging first, not complexity yet.
Current pass count is ${passedCount}/${totalCount}.

Pick one failing case and trace input -> branch condition -> returned value line by line.
Share one failing example and I can walk through the exact break point with you.

(${statusNote})`
  }

  return `Pass! Nice work. You are at ${passedCount}/${totalCount}.

Now we can optimize:
- Time: if there are nested loops, check if Map/Set can reduce it.
- Space: verify the trade-off for auxiliary structures.
- Naming: replace short names with role-based names like left/countMap/current.

If you want, I can suggest concrete refactors on your current code.

(${statusNote})`
}

async function reviewWithClaude(
  code: string,
  problemTitle: string,
  problemDescription: string,
  testResults: TestResult[],
  allTestsPassed: boolean,
  language: MentorLanguage,
  apiKey: string,
  model: string,
  maxOutputTokens: number
): Promise<string> {
  const passedCount = testResults.filter((r) => r.passed).length
  const totalCount = testResults.length

  const prompt = `You are a **Supportive Coding Mentor** reviewing a student's solution for: "${problemTitle}"

**Problem Description:**
${problemDescription}

**Student's Code:**
\`\`\`javascript
${code}
\`\`\`

**Test Results:** ${passedCount}/${totalCount} tests passed

${testResults
  .map(
    (r, i) => `Test ${i + 1}: ${r.passed ? "âœ“ PASSED" : "âœ— FAILED"}
${!r.passed ? `  Input: ${r.input}\n  Expected: ${r.expected}\n  Got: ${r.actual}` : ""}`
  )
  .join("\n")}

**Mentoring Mode:**
- Keep the tone natural and conversational, like pair programming chat.
- Avoid rigid report sections or formal header templates.
- Use the test output as the first source of truth.
- ${allTestsPassed ? "All tests passed: congratulate briefly, then cover optimization (time/space), naming clarity, and production-ready refactoring." : "Tests failed: focus only on debugging root cause first. Trace line-by-line and explain why the output diverges. Do not discuss complexity yet."}
- Suggest algorithm alternatives naturally (Two Pointers / Stack / Hash Map trade-offs) when relevant.
- Do not dump a full solution unless explicitly requested.

Provide your supportive feedback now:

${getMentorPersonaInstruction(language)}
${getMentorLanguageInstruction(language)}`

  const result = await generateText({
    model: getLanguageModel("claude", model, apiKey),
    prompt,
    maxOutputTokens,
    temperature: 0.7,
  })
  return result.text
}

async function reviewWithGPT(
  code: string,
  problemTitle: string,
  problemDescription: string,
  testResults: TestResult[],
  allTestsPassed: boolean,
  language: MentorLanguage,
  apiKey: string,
  model: string,
  maxOutputTokens: number
): Promise<string> {
  const passedCount = testResults.filter((r) => r.passed).length
  const totalCount = testResults.length

  const prompt = `You are a **Supportive Coding Mentor** reviewing a student's solution for: "${problemTitle}"

**Problem Description:**
${problemDescription}

**Student's Code:**
\`\`\`javascript
${code}
\`\`\`

**Test Results:** ${passedCount}/${totalCount} tests passed

${testResults
  .map(
    (r, i) => `Test ${i + 1}: ${r.passed ? "âœ“ PASSED" : "âœ— FAILED"}
${!r.passed ? `  Input: ${r.input}\n  Expected: ${r.expected}\n  Got: ${r.actual}` : ""}`
  )
  .join("\n")}

**Mentoring Mode:**
- Keep the tone natural and conversational, like pair programming chat.
- Avoid rigid report sections or formal header templates.
- Use the test output as the first source of truth.
- ${allTestsPassed ? "All tests passed: congratulate briefly, then cover optimization (time/space), naming clarity, and production-ready refactoring." : "Tests failed: focus only on debugging root cause first. Trace line-by-line and explain why the output diverges. Do not discuss complexity yet."}
- Suggest algorithm alternatives naturally (Two Pointers / Stack / Hash Map trade-offs) when relevant.
- Do not dump a full solution unless explicitly requested.

Provide your supportive feedback now:

${getMentorPersonaInstruction(language)}
${getMentorLanguageInstruction(language)}`

  const result = await generateText({
    model: getLanguageModel("gpt", model, apiKey),
    system:
      "You are a helpful coding mentor who provides constructive feedback and guides students to learn.",
    prompt,
    maxOutputTokens,
    temperature: 0.7,
  })
  return result.text
}

async function reviewWithGemini(
  code: string,
  problemTitle: string,
  problemDescription: string,
  testResults: TestResult[],
  allTestsPassed: boolean,
  language: MentorLanguage,
  apiKey: string,
  model: string,
  maxOutputTokens: number
): Promise<string> {
  const passedCount = testResults.filter((r) => r.passed).length
  const totalCount = testResults.length

  const prompt = `You are a **Supportive Coding Mentor** reviewing a student's solution for: "${problemTitle}"

**Problem Description:**
${problemDescription}

**Student's Code:**
\`\`\`javascript
${code}
\`\`\`

**Test Results:** ${passedCount}/${totalCount} tests passed

${testResults
  .map(
    (r, i) => `Test ${i + 1}: ${r.passed ? "âœ“ PASSED" : "âœ— FAILED"}
${!r.passed ? `  Input: ${r.input}\n  Expected: ${r.expected}\n  Got: ${r.actual}` : ""}`
  )
  .join("\n")}

**Mentoring Mode:**
- Keep the tone natural and conversational, like pair programming chat.
- Avoid rigid report sections or formal header templates.
- Use the test output as the first source of truth.
- ${allTestsPassed ? "All tests passed: congratulate briefly, then cover optimization (time/space), naming clarity, and production-ready refactoring." : "Tests failed: focus only on debugging root cause first. Trace line-by-line and explain why the output diverges. Do not discuss complexity yet."}
- Suggest algorithm alternatives naturally (Two Pointers / Stack / Hash Map trade-offs) when relevant.
- Do not dump a full solution unless explicitly requested.

Provide your supportive feedback now:

${getMentorPersonaInstruction(language)}
${getMentorLanguageInstruction(language)}`

  const result = await generateText({
    model: getLanguageModel("gemini", model, apiKey),
    prompt,
    maxOutputTokens,
    temperature: 0.7,
  })
  return result.text
}

export async function POST(req: NextRequest) {
  try {
    const body: ReviewRequest = await req.json()
    const { code, problemTitle, problemDescription, testResults, allTestsPassed } = body
    const language = resolveMentorLanguage(body.language, [problemTitle, problemDescription])

    const config = resolveAIConfig(body.aiConfig)

    let feedback: string

    try {
      let resolved: string | null = null
      for (const provider of providerCandidates(config)) {
        const apiKey = config.apiKeys[provider]?.trim()
        if (!apiKey) {
          continue
        }

        try {
          if (provider === "claude") {
            resolved = await reviewWithClaude(
              code,
              problemTitle,
              problemDescription,
              testResults,
              allTestsPassed,
              language,
              apiKey,
              config.models.claude,
              config.maxTokens.claude
            )
            break
          }

          if (provider === "gpt") {
            resolved = await reviewWithGPT(
              code,
              problemTitle,
              problemDescription,
              testResults,
              allTestsPassed,
              language,
              apiKey,
              config.models.gpt,
              config.maxTokens.gpt
            )
            break
          }

          resolved = await reviewWithGemini(
            code,
            problemTitle,
            problemDescription,
            testResults,
            allTestsPassed,
            language,
            apiKey,
            config.models.gemini,
            config.maxTokens.gemini
          )
          break
        } catch (error) {
          console.error(`AI API error (${provider}):`, error)
        }
      }

      if (resolved) {
        feedback = resolved
      } else {
        feedback = generateFallbackReviewFeedback(
          language,
          testResults.filter((r) => r.passed).length,
          testResults.length,
          allTestsPassed,
          "no-key"
        )
      }
    } catch (error) {
      console.error("AI API error:", error)
      feedback = generateFallbackReviewFeedback(
        language,
        testResults.filter((r) => r.passed).length,
        testResults.length,
        allTestsPassed,
        "service-error"
      )
    }

    return NextResponse.json({ feedback })
  } catch (error) {
    console.error("Error in code review:", error)
    return NextResponse.json({ feedback: "An error occurred while reviewing your code." }, { status: 500 })
  }
}
