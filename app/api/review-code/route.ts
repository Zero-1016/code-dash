import { NextRequest, NextResponse } from "next/server"
import { generateText } from "ai"
import {
  providerCandidates,
  resolveAIConfig,
  type AIConfigPayload,
} from "@/lib/ai-config"
import { getLanguageModel } from "@/lib/server/ai-model"
import {
  getMentorPersonaInstruction,
  getMentorReviewFormatInstruction,
  getMentorLanguageInstruction,
  resolveMentorLanguage,
  type MentorLanguage,
} from "@/lib/mentor-language"

interface TestResult {
  passed: boolean
  input: string
  expected: string
  actual: string
}

interface ReviewRequest {
  code: string
  problemTitle: string
  problemDescription: string
  testResults: TestResult[]
  allTestsPassed: boolean
  language?: MentorLanguage
  aiConfig?: Partial<AIConfigPayload>
}

function generateFallbackReviewFeedback(
  language: MentorLanguage,
  passedCount: number,
  totalCount: number,
  allTestsPassed: boolean,
  note: "no-key" | "service-error"
): string {
  const statusNote =
    note === "no-key"
      ? language === "ko"
        ? "í˜„ì¬ API Keyê°€ ì—†ì–´ AI ì‹¬ì¸µ ë¶„ì„ì€ ì œí•œë¼ìš”. ê·¸ë˜ë„ ë©˜í†  í¬ë§·ìœ¼ë¡œ í•µì‹¬ì„ ì§šì–´ì¤„ê²Œìš”."
        : "No API key is configured, so deep AI analysis is limited. Here is a mentor-style review."
      : language === "ko"
        ? "AI ì—°ê²°ì´ ì¼ì‹œì ìœ¼ë¡œ ë¶ˆì•ˆì •í•´ë„, ì§€ê¸ˆ ê²°ê³¼ ê¸°ì¤€ìœ¼ë¡œ ë©˜í†  ë¦¬ë·°ë¥¼ ì´ì–´ê°ˆê²Œìš”."
        : "AI service is temporarily unstable, but here is a mentor-style review from current results."

  if (language === "ko") {
    return `### ğŸ“Š Complexity Report
- Time Complexity: í˜„ì¬ ì½”ë“œë¥¼ ì§ì ‘ ì‹¤í–‰ ë¶„ì„í•˜ì§„ ëª»í•˜ì§€ë§Œ, í…ŒìŠ¤íŠ¸ í†µê³¼ìœ¨ì€ ${passedCount}/${totalCount}ì…ë‹ˆë‹¤. ${allTestsPassed ? "ë°˜ë³µ êµ¬ì¡°ë¥¼ í•œ ë‹¨ê³„ ì¤„ì¼ ìˆ˜ ìˆëŠ”ì§€(O(n^2) -> O(n) ê°€ëŠ¥ì„±) ì ê²€í•´ë³´ì„¸ìš”." : "ì‹¤íŒ¨ ì¼€ì´ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„ê¸° ì¡°ê±´ì´ ë¶ˆí•„ìš”í•˜ê²Œ ì¤‘ì²©ë˜ì§€ ì•Šì•˜ëŠ”ì§€ ë¨¼ì € í™•ì¸í•˜ì„¸ìš”."}
- Space Complexity: ë³´ì¡° ìë£Œêµ¬ì¡°(Map/Set/ë°°ì—´)ë¥¼ ì–´ë””ì— ì“°ëŠ”ì§€ ê¸°ì¤€ìœ¼ë¡œ ê³µê°„ ì‚¬ìš©ì„ ì ê²€í•˜ì„¸ìš”. ë¶ˆí•„ìš”í•œ ë³µì‚¬ë‚˜ ì¤‘ê°„ ë°°ì—´ ìƒì„±ì´ ìˆìœ¼ë©´ ì¤„ì´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.

### ğŸ·ï¸ Naming & Clean Code
- Variable Naming: ë‹¨ì¶• ë³€ìˆ˜ëª…('i', 'm', 'tmp')ì€ ì—­í•  ê¸°ë°˜ ì´ë¦„('left', 'countMap', 'currentSum')ìœ¼ë¡œ ë°”ê¾¸ë©´ ë””ë²„ê¹… ì†ë„ê°€ ë¹¨ë¼ì§‘ë‹ˆë‹¤.
- Refactoring: ì¡°ê±´ë¬¸ì„ í•¨ìˆ˜ë¡œ ë¶„ë¦¬í•˜ê³ , ìƒìˆ˜ë¥¼ 'const'ë¡œ ëª…ì‹œí•´ ì˜ë„ë¥¼ ë“œëŸ¬ë‚´ì„¸ìš”. TypeScriptì—ì„œëŠ” ì…ë ¥/ì¶œë ¥ íƒ€ì…ì„ ë¨¼ì € ê³ ì •í•˜ë©´ ì‹¤ìˆ˜ë¥¼ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ’¡ Friendly Deep-dive
ë¬¸ì œ í•´ê²°ì€ "ì •ë‹µ ë§íˆê¸°"ë³´ë‹¤ "íë¦„ ê³ ì •"ì´ ë” ì¤‘ìš”í•´ìš”. ì§€ê¸ˆì€ ì‹¤íŒ¨í•˜ëŠ” í…ŒìŠ¤íŠ¸ 1ê°œë¥¼ ê³¨ë¼ì„œ ì…ë ¥ì´ ë“¤ì–´ì˜¨ ë’¤ ê°’ì´ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ í•œ ì¤„ì”© ì¶”ì í•´ë³´ì„¸ìš”. Mapì€ ë©”ëª¨ì¥ì²˜ëŸ¼ "ì´ë¯¸ ë³¸ ì •ë³´"ë¥¼ ë¹ ë¥´ê²Œ êº¼ë‚´ ì“°ëŠ” ë„êµ¬ë¼ì„œ, ë°˜ë³µë¬¸ì„ ì¤„ì¼ ë•Œ íŠ¹íˆ ê°•í•©ë‹ˆë‹¤.

_Note: ${statusNote}_`
  }

  return `### ğŸ“Š Complexity Report
- Time Complexity: Direct runtime analysis is limited right now. Current pass rate is ${passedCount}/${totalCount}. ${allTestsPassed ? "Check whether nested loops can be reduced." : "Start with the first failing case and validate branch conditions."}
- Space Complexity: Review where auxiliary structures (Map/Set/arrays) are used and remove unnecessary copies.

### ğŸ·ï¸ Naming & Clean Code
- Variable Naming: Replace short names with role-based names like \`left\`, \`countMap\`, \`currentSum\`.
- Refactoring: Extract branch logic into small functions and make intent explicit with strong TypeScript typing.

### ğŸ’¡ Friendly Deep-dive
Focus on one failing case and trace state changes line by line. Think of Map as a quick-access notebook for things you've already seen.

_Note: ${statusNote}_`
}

async function reviewWithClaude(
  code: string,
  problemTitle: string,
  problemDescription: string,
  testResults: TestResult[],
  allTestsPassed: boolean,
  language: MentorLanguage,
  apiKey: string,
  model: string,
  maxOutputTokens: number
): Promise<string> {
  const passedCount = testResults.filter((r) => r.passed).length
  const totalCount = testResults.length

  const prompt = `You are a **Supportive Coding Mentor** reviewing a student's solution for: "${problemTitle}"

**Problem Description:**
${problemDescription}

**Student's Code:**
\`\`\`javascript
${code}
\`\`\`

**Test Results:** ${passedCount}/${totalCount} tests passed

${testResults
  .map(
    (r, i) => `Test ${i + 1}: ${r.passed ? "âœ“ PASSED" : "âœ— FAILED"}
${!r.passed ? `  Input: ${r.input}\n  Expected: ${r.expected}\n  Got: ${r.actual}` : ""}`
  )
  .join("\n")}

**Your Role as a Supportive Coding Mentor:**
Your goal is to help the student **think like a developer** and grow their problem-solving skills. You're not here to just point out mistakes, but to guide them toward understanding.

**Your Task:**
1. **Analyze**: Look at their approach and logic
2. **Encourage**: Recognize what they did well, even if tests are failing
3. **Guide**: ${allTestsPassed ? "Suggest how they might optimize or refactor their solution" : "Ask thoughtful questions to help them discover what's wrong (don't give away the answer!)"}
4. **Teach**: Help them understand the 'why' behind the issue or improvement

**Guidelines:**
- Be warm, encouraging, and supportive
- Celebrate their progress and effort
- If tests are failing, use guiding questions like "What happens when...?" or "Have you considered...?"
- Help them build their debugging intuition
- Keep feedback concise but insightful (3-4 short paragraphs)
- Use a friendly, conversational tone
- Format with markdown for readability

Provide your supportive feedback now:

${getMentorPersonaInstruction(language)}
${getMentorReviewFormatInstruction(language)}
${getMentorLanguageInstruction(language)}`

  const result = await generateText({
    model: getLanguageModel("claude", model, apiKey),
    prompt,
    maxOutputTokens,
    temperature: 0.7,
  })
  return result.text
}

async function reviewWithGPT(
  code: string,
  problemTitle: string,
  problemDescription: string,
  testResults: TestResult[],
  allTestsPassed: boolean,
  language: MentorLanguage,
  apiKey: string,
  model: string,
  maxOutputTokens: number
): Promise<string> {
  const passedCount = testResults.filter((r) => r.passed).length
  const totalCount = testResults.length

  const prompt = `You are a **Supportive Coding Mentor** reviewing a student's solution for: "${problemTitle}"

**Problem Description:**
${problemDescription}

**Student's Code:**
\`\`\`javascript
${code}
\`\`\`

**Test Results:** ${passedCount}/${totalCount} tests passed

${testResults
  .map(
    (r, i) => `Test ${i + 1}: ${r.passed ? "âœ“ PASSED" : "âœ— FAILED"}
${!r.passed ? `  Input: ${r.input}\n  Expected: ${r.expected}\n  Got: ${r.actual}` : ""}`
  )
  .join("\n")}

**Your Role as a Supportive Coding Mentor:**
Your goal is to help the student **think like a developer** and grow their problem-solving skills. You're not here to just point out mistakes, but to guide them toward understanding.

**Your Task:**
1. **Analyze**: Look at their approach and logic
2. **Encourage**: Recognize what they did well, even if tests are failing
3. **Guide**: ${allTestsPassed ? "Suggest how they might optimize or refactor their solution" : "Ask thoughtful questions to help them discover what's wrong (don't give away the answer!)"}
4. **Teach**: Help them understand the 'why' behind the issue or improvement

**Guidelines:**
- Be warm, encouraging, and supportive
- Celebrate their progress and effort
- If tests are failing, use guiding questions like "What happens when...?" or "Have you considered...?"
- Help them build their debugging intuition
- Keep feedback concise but insightful (3-4 short paragraphs)
- Use a friendly, conversational tone
- Format with markdown for readability

Provide your supportive feedback now:

${getMentorPersonaInstruction(language)}
${getMentorReviewFormatInstruction(language)}
${getMentorLanguageInstruction(language)}`

  const result = await generateText({
    model: getLanguageModel("gpt", model, apiKey),
    system:
      "You are a helpful coding mentor who provides constructive feedback and guides students to learn.",
    prompt,
    maxOutputTokens,
    temperature: 0.7,
  })
  return result.text
}

async function reviewWithGemini(
  code: string,
  problemTitle: string,
  problemDescription: string,
  testResults: TestResult[],
  allTestsPassed: boolean,
  language: MentorLanguage,
  apiKey: string,
  model: string,
  maxOutputTokens: number
): Promise<string> {
  const passedCount = testResults.filter((r) => r.passed).length
  const totalCount = testResults.length

  const prompt = `You are a **Supportive Coding Mentor** reviewing a student's solution for: "${problemTitle}"

**Problem Description:**
${problemDescription}

**Student's Code:**
\`\`\`javascript
${code}
\`\`\`

**Test Results:** ${passedCount}/${totalCount} tests passed

${testResults
  .map(
    (r, i) => `Test ${i + 1}: ${r.passed ? "âœ“ PASSED" : "âœ— FAILED"}
${!r.passed ? `  Input: ${r.input}\n  Expected: ${r.expected}\n  Got: ${r.actual}` : ""}`
  )
  .join("\n")}

**Your Role as a Supportive Coding Mentor:**
Your goal is to help the student **think like a developer** and grow their problem-solving skills. You're not here to just point out mistakes, but to guide them toward understanding.

**Your Task:**
1. **Analyze**: Look at their approach and logic
2. **Encourage**: Recognize what they did well, even if tests are failing
3. **Guide**: ${allTestsPassed ? "Suggest how they might optimize or refactor their solution" : "Ask thoughtful questions to help them discover what's wrong (don't give away the answer!)"}
4. **Teach**: Help them understand the 'why' behind the issue or improvement

**Guidelines:**
- Be warm, encouraging, and supportive
- Celebrate their progress and effort
- If tests are failing, use guiding questions like "What happens when...?" or "Have you considered...?"
- Help them build their debugging intuition
- Keep feedback concise but insightful (3-4 short paragraphs)
- Use a friendly, conversational tone
- Format with markdown for readability

Provide your supportive feedback now:

${getMentorPersonaInstruction(language)}
${getMentorReviewFormatInstruction(language)}
${getMentorLanguageInstruction(language)}`

  const result = await generateText({
    model: getLanguageModel("gemini", model, apiKey),
    prompt,
    maxOutputTokens,
    temperature: 0.7,
  })
  return result.text
}

export async function POST(req: NextRequest) {
  try {
    const body: ReviewRequest = await req.json()
    const { code, problemTitle, problemDescription, testResults, allTestsPassed } = body
    const language = resolveMentorLanguage(body.language, [problemTitle, problemDescription])

    const config = resolveAIConfig(body.aiConfig)

    let feedback: string

    try {
      let resolved: string | null = null
      for (const provider of providerCandidates(config)) {
        const apiKey = config.apiKeys[provider]?.trim()
        if (!apiKey) {
          continue
        }

        try {
          if (provider === "claude") {
            resolved = await reviewWithClaude(
              code,
              problemTitle,
              problemDescription,
              testResults,
              allTestsPassed,
              language,
              apiKey,
              config.models.claude,
              config.maxTokens.claude
            )
            break
          }

          if (provider === "gpt") {
            resolved = await reviewWithGPT(
              code,
              problemTitle,
              problemDescription,
              testResults,
              allTestsPassed,
              language,
              apiKey,
              config.models.gpt,
              config.maxTokens.gpt
            )
            break
          }

          resolved = await reviewWithGemini(
            code,
            problemTitle,
            problemDescription,
            testResults,
            allTestsPassed,
            language,
            apiKey,
            config.models.gemini,
            config.maxTokens.gemini
          )
          break
        } catch (error) {
          console.error(`AI API error (${provider}):`, error)
        }
      }

      if (resolved) {
        feedback = resolved
      } else {
        feedback = generateFallbackReviewFeedback(
          language,
          testResults.filter((r) => r.passed).length,
          testResults.length,
          allTestsPassed,
          "no-key"
        )
      }
    } catch (error) {
      console.error("AI API error:", error)
      feedback = generateFallbackReviewFeedback(
        language,
        testResults.filter((r) => r.passed).length,
        testResults.length,
        allTestsPassed,
        "service-error"
      )
    }

    return NextResponse.json({ feedback })
  } catch (error) {
    console.error("Error in code review:", error)
    return NextResponse.json({ feedback: "An error occurred while reviewing your code." }, { status: 500 })
  }
}
